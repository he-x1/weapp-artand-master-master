"""
æ•°æ®å¯¼å…¥è„šæœ¬
"""
import sys
import os

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app import create_app
from app.models import db, Culture, Category
from crawler import CultureCrawler
from loguru import logger
import json


def import_to_database(data_list):
    """å°†çˆ¬å–çš„æ•°æ®å¯¼å…¥æ•°æ®åº“"""
    app = create_app()

    with app.app_context():
        try:
            imported_count = 0

            for item in data_list:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ ¹æ®åç§°å»é‡ï¼‰
                existing = Culture.query.filter_by(name=item['name']).first()
                if existing:
                    logger.info(f'æ•°æ®å·²å­˜åœ¨ï¼Œè·³è¿‡: {item["name"]}')
                    continue

                # åˆ›å»ºæ–°çš„æ–‡åŒ–å†…å®¹è®°å½•
                culture = Culture(
                    name=item['name'],
                    category_id=item['category_id'],
                    description=item.get('description', ''),
                    summary=item.get('summary', ''),
                    origin=item.get('origin', 'ä¸­å›½'),
                    heritage_level=item.get('heritage_level'),
                    cover_image=item.get('cover_image'),
                    source=item.get('source', ''),
                    source_url=item.get('source_url', ''),
                    status=1,  # å·²å‘å¸ƒ
                    is_recommend=True,
                    score=50.0 + len(item.get('description', '')) / 100  # åŸºç¡€åˆ†æ•°
                )

                db.session.add(culture)
                imported_count += 1

                if imported_count % 10 == 0:
                    db.session.commit()
                    logger.info(f'å·²å¯¼å…¥ {imported_count} æ¡æ•°æ®')

            db.session.commit()
            logger.info(f'âœ… å¯¼å…¥å®Œæˆï¼Œå…±å¯¼å…¥ {imported_count} æ¡æ–°æ•°æ®')

            return imported_count

        except Exception as e:
            db.session.rollback()
            logger.error(f'âŒ å¯¼å…¥å¤±è´¥: {e}')
            return 0


def update_statistics():
    """æ›´æ–°ç»Ÿè®¡æ•°æ®"""
    app = create_app()

    with app.app_context():
        # æ›´æ–°åˆ†ç±»è®¡æ•°
        categories = Category.query.all()
        for category in categories:
            count = Culture.query.filter_by(category_id=category.id, status=1).count()
            logger.info(f'{category.name}: {count} ç¯‡å†…å®¹')


def main():
    """ä¸»å‡½æ•°"""
    logger.info('ğŸš€ å¼€å§‹çˆ¬å–æ•°æ®...')

    # 1. çˆ¬å–æ•°æ®
    crawler = CultureCrawler(upload_folder='../uploads')
    data_list = crawler.crawl_all()

    if not data_list:
        logger.warning('âš ï¸ æ²¡æœ‰çˆ¬å–åˆ°æ•°æ®')
        return

    logger.info(f'ğŸ“Š å…±çˆ¬å– {len(data_list)} æ¡æ•°æ®')

    # 2. ä¿å­˜åŸå§‹æ•°æ®
    with open('crawled_data.json', 'w', encoding='utf-8') as f:
        json.dump(data_list, f, ensure_ascii=False, indent=2)
    logger.info('ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° crawled_data.json')

    # 3. å¯¼å…¥æ•°æ®åº“
    imported = import_to_database(data_list)

    # 4. æ›´æ–°ç»Ÿè®¡
    update_statistics()

    logger.info(f'âœ¨ å®Œæˆï¼æ–°å¢ {imported} æ¡æ•°æ®')


if __name__ == '__main__':
    main()